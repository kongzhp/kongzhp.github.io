---
layout:     post
title:      "Cassandra使用笔记（3）"
subtitle:   "Database internals"
date:       2015-08-19 19:35:00
author:     "Pete Kong"
header-img: "img/post-bg-02.jpg"
---

# Cassandra存储基础
-----------------

## write path to compaction

Cassandra的写路径会包含以下几个阶段，从记录写日志开始，到compaction结束。

1. 记录写日志和memtable存储

	当发生写操作，cassandra会把数据存储到一个在内存中叫memtable的数据结构里，同时把写操作append到磁盘的commit log里，即使断电了，commit log都会保留。memtable会保存写数据直到达到阈值，然后flush。

2. 从memtable flush到磁盘

	当memtable的内容超过配置的阈值，memtable的数据（包括索引）就会放到队列里等待flush到磁盘。你也可以配置queue的大小：memtable_heap_space_in_mb .如果队列也满了，那么写操作将会被阻塞直到flush成功。你也可以手工的调nodetool flush命令来flush。在重启节点之前，一般都需要手工flush memtable，以减少commit log replay的时间。

3. 把数据保存到磁盘上的SSTables
	
	当memtable的数据被flush到SSTable后，commit log也会被清除。

	![storage]({{ site.baseurl }}/img/cassandra03/storage_basic.png)

	Memtables和SSTables为每个table维护一份。SSTtables是不可变的，在memtable flush过去之后就不会被修改，因此，一个partition一般会存储在多个SSTable文件里。

4. Compaction
	
	cassandra会定期的进行数据压缩，因为当发生update/insert时，cassandra不会针对找到需要修改的数据的位置去进行重写，只会在另一个SSTable里新加一条数据，并加上version信息。因此，cassandra需要对不断累积的SSTable进行压缩。

	同样，delete也是不会在SSTable里把数据删除，而是使用tombstone来标记数据将要被删除。Tomstone会保存一段时间，它是由gc_grace_seconds这个配置项定义。

	在压缩过程中，磁盘利用率会达到一个临时的峰值，下图描述了压缩的过程：

	![compaction]({{ site.baseurl }}/img/cassandra03/compaction.png)

	压缩过程中，每个SSTable里的数据会根据partition key进行合并，根据timestamp选取最新的那条数据。cassandra合并数据是非常高效的，因为在每个SSTable里的行都是根据partition key来排序。删除完被标记了tombstones的数据，压缩进程会把SSTables更新到一个新的文件。就得SSTable则会在所有等待的读完成后删除。然后旧的SSTable所占空间则可被重用。

	你可以配置以下3种压缩类型：

	* [SizeTieredCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) : 业务类型是写敏感的
	* [LeveledCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) ：业务类型是读敏感的
	* [DateTieredCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) ：[ time series data ](http://planetcassandra.org/blog/getting-started-with-time-series-data-modeling/) 和 [expiring (TTL) data](http://docs.datastax.com/en/cql/3.1/cql/cql_using/use_expire_c.html)

## 索引存储和更新
	
在cassandra里，索引是一个数据分区。例如在palylist的例子里，为artist字段创建索引，cassandra根据playlist id作为partition key把数据保存到不同的节点上，每个节点会为自己拥有的artist信息创建索引。

和关系型数据库一样，更新索引也不是完全没有消耗的，所以不要创建无谓的索引。当一列数据被更新，索引页也需要更新。

# delete
---------------------------------

Cassandra删除数据的方式与关系型数据库不一样，关系新数据库会先查找数据然后删除，而cassandra的数据将会有一个可选的属性：TTL（tiem to live）。通过使用CQL为数据设置TTL，cassandra将会把过期的数据标记tombstone，tombstone会存在gc_grace_seconds长的时间，并在compaction阶段把它删除。被删除的数据也是有可能被恢复的，因为删除某一个行数据时，拥有这数据的replica的节点挂了，而且挂的时间比较长，删除请求不能replay到那个节点上，那么数据就会保留在那个节点。

# Hinted handoff
----------------------------------

Hinted handoff是cassandra优化cluster consitency进程和cluster数据同步的特性。当某个节点不可用时，在一定的一致性level配置情况下，启用了hinted handoff可以保证写成功。

在写的过程中，假如需要保存replica的某个节点不可用（1.预先知道该节点不可用 2.向该节点发写请求没回应），并且符合一致性要求的情况下，coordinator(接收到客户端发来的写请求的节点)将会保存replica的hint.hint包含了以下信息：

* 需要保存该replica节点位置
* version metadata
* 真正的数据

hints默认会被保存3个小时，因为超过3个小时那个节点还没起来可能永久的挂了。如果节点恢复了，保存hints的节点将会把数据重新发送给那个节点。

当W+R>replication factor的时候，写操作将会失败。其中W是block住写的节点，R是block住读的节点。例如cluster里有两个节点A和B，replication factor（RF）是1（即每一行数据只有一份），假设现在A挂了，并有一个要向A写的数据K的请求，一致性level是1，这时请求将会失败。因为一致性level是1，要求至少有一个replia可用，那么R=1，W=1，R+W=2>RF(=1）,所以写失败，hinted也不会保存。如果一个cluster里有3个节点,A(coordinator)/B和C，RF=2，每行数据都会存在于两个节点上。假如C挂了，一致性level是ONE，A节点接收到客户端的写请求，那么A将会往B写一份，自己也会保存hint。当C恢复，A将把数据转发给C。
![hinthandoff]({{ site.baseurl }}/img/cassandra03/hinthandoff.png)

## Extreme write availability

如果希望cassndra在所有replica的节点都down的情况下都成功接收写请求，那么就把一致性level设置为ANY，保证写是可持久化的，并且当合适的replica节点恢复后，那么数据就可读。


# Reads
---------------------------

Cassandra必须同时结合memtable和潜在的多个SSTables去完成一个读请求。首先，cassandra会检查bloom filter, bloom filter是一个off-heap（堆外内存）数据结构，关联着每个SSTable，记录了请求的数据行是否存在于SSTtable中，减少多余磁盘IO。

如果Bloom filter没有排除掉SSTable，cassandra会检查partition key cache会根据以下情况采取不同的action：

* 如果index entry在cache里找到：

	1. cassndra会去compression offset map里找到存储数据的compressed block
	2. 抓取compressed数据并返回结果

* 如果在cache没找到到index entry

	1. cassandra在partition summary里查找index entry的在磁盘中的大概位置。partiton summary是partition index 的子集，它会把每128个partition index中抽取一个放到partition summary，默认从index 1开始.而partition index保存了主键和数据在磁盘中的为位置。
	2. 然后抓取index entry
	3. 去compression offset map里找到存储数据的compressed block
	4. 抓取compressed数据并返回结果
![read]({{ site.baseurl }}/img/cassandra03/read.png)

## off-heap 组件对reads的影响

为了提高每个节点处理数据的能力，cassandra把以下组件放置到堆外内存上。

* bloom filter : 

	[bloom filter](http://billmill.org/bloomfilter-tutorial/)是用于查找某个数据是否在集合中的算法，它使用一个bit map标记某个数据是否存在，例如某个集合里有A数据，那么通过一个哈希函数算出A在bit map里的比特位置，并设置为1。那么要查找A时，用同样的哈希算法算出比特位置，假如这个位是1，代表A数据存在，如果是0，则不存在。

	每10亿个partitions就会让bloom filter增长1-2G。在极端的case里，你可以每一行拥有一个partition（？？？）。所以在一台机器里，你可以很容易拥有十亿个partition。你也可以调节bloom filter来调优性能。

* partition summary

	partiton summary是partition index的样本，你可以配置表定义的index_interval属性来修改采样频率。

* Compression offsets

	每TB的数据被压缩时，compression offset map增长1-3G。你压缩的数据越多，压缩的block的数目就越多，而compression offset的表就越大。

## Compaction 策略对reads的影响

SizeTieredCompactionStrategy和DateTieredCompactionStrategy都会在行不断地更新的过程中造成数据碎片。而[LeveledCompactionStrategy](http://www.datastax.com/dev/blog/leveled-compaction-in-apache-cassandra)就可以解决这个问题。

# 事务和并发控制

Cassandra不使用关系型数据库的rollback或者锁机制的ACID事务，但提供可调节一致性的原子性、隔离和持久性事务，让用户自己决定事务一致性的程度。

* 原子性： 在一个事务中，要么所有操作执行成功，要么全部rolled back
* 一致性： 事务不能让数据库处于不一致的状态。
* 隔离性： 事务之间不会互相影响。
* 持久性： 事务能够持久化

作为一个非关系型数据库，Cassandra不支持联表查询或者外键，所以不提供在ACID意义上的一致性（保持外键约束）。cassandra支持行级的原子性和隔离性，把事务的隔离性和原子性换来高可用和高效的性能。

## 原子性

在Cassandra里，写是partition-level的原子性，那就意味着插入和更新一行数据里的列是当作一次写操作。删除也是原子性。默认情况下，所有批量操作都是原子性的，cassandra会使用一个batch log来确保批量操作的原子性。如果一个批量操作跨了几个Partiton的话就会带来性能的降低，如果你不想性能降低，可以使用[UNLOGGED](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/batch_r.html)选项（执行BATCH的CQL时加上UNLOGGED），这样batch操作只会在单个partition里保证原子。

例如，如果Replication factor是3，写一致性level是QUORUM，cassandra会把写操作发送到cluster里的所有节点，并等待两个节点的确认信息。假如一个节点写成功，另一个失败，cassandra会报告在哪个节点上复制失败，但是复制成功的那个节点不会自动roll back。

Cassandra使用时间戳来标记某一列谁是最新的值。如果 多个client session并发地更新同一行的列，那么最近的一次更新会被读取到。

## 隔离性

在前期的版本中，用户在往一行数据的某些列进行更新的时候，例如一行中有两千多列，其他用户都可以读取这一行的某些列，尽管写并没有完全完成。而现在是整个行级的隔离，也就是说当这一行数据在更新的时候，其他用户需要等待更新完成才可以读；删除操作也是隔离的。属于同一个partitton key的批操作也是隔离的。

## 持久性

所有往replica节点的写被记录在内存还有commit log里，当他们都完成后才返回确认信息。如果服务器在memtable flush到磁盘之前挂了，节点重启的时候也可以通过commit log 恢复丢失掉的写。除了本地的持久化，在其他节点的replia也是加强了持久性。

## 轻量级事务

轻量级事务的线性一致性确保了事务的隔离级别近似于关系型数据库的串行化级别。也可以看做‘比较后设置’的事务。例如，两个用户同时创建 一个user account，他们可能会覆盖了对方的操作。使用轻量级事务时，节点可以只创建一个account。

Cassandra扩展了[Paxos consensus protocol](http://blog.csdn.net/russell_tao/article/details/7244530)实现轻量级事务，它是一个quorun-base的算法。通过使用这个协议，分布式系统可以不需要master数据库或者两阶段提交来一个插入/修改操作。


你可以使用扩展的CQL来实现轻量级事务：

	INSERT INTO customer_account (customerID, customer_email) 
	VALUES (‘LauraS’, ‘lauras@gmail.com’)
	IF NOT EXISTS;

	UPDATE customer_account
	SET    customer_email=’laurass@gmail.com’
	IF     customerID=’LauraS’;







