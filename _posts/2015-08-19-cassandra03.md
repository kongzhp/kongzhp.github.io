---
layout:     post
title:      "Cassandra使用笔记（3）"
subtitle:   "Database internals"
date:       2015-08-19 19:35:00
author:     "Pete Kong"
header-img: "img/post-bg-02.jpg"
---

# Cassandra存储基础
-----------------

## write path to compaction

Cassandra的写路径会包含以下几个阶段，从记录写日志开始，到compaction结束。

1. 记录写日志和memtable存储

	当发生写操作，cassandra会把数据存储到一个在内存中叫memtable的数据结构里，同时把写操作append到磁盘的commit log里，即使断电了，commit log都会保留。memtable会保存写数据直到达到阈值，然后flush。

2. 从memtable flush到磁盘

	当memtable的内容超过配置的阈值，memtable的数据（包括索引）就会放到队列里等待flush到磁盘。你也可以配置queue的大小：memtable_heap_space_in_mb .如果队列也满了，那么写操作将会被阻塞直到flush成功。你也可以手工的调nodetool flush命令来flush。在重启节点之前，一般都需要手工flush memtable，以减少commit log replay的时间。

3. 把数据保存到磁盘上的SSTables
	
	当memtable的数据被flush到SSTable后，commit log也会被清除。

	![storage]({{ site.baseurl }}/img/cassandra03/storage_basic.png)

	Memtables和SSTables为每个table维护一份。SSTtables是不可变的，在memtable flush过去之后就不会被修改，因此，一个partition一般会存储在多个SSTable文件里。

4. Compaction
	
	cassandra会定期的进行数据压缩，因为当发生update/insert时，cassandra不会针对找到需要修改的数据的位置去进行重写，只会在另一个SSTable里新加一条数据，并加上version信息。因此，cassandra需要对不断累积的SSTable进行压缩。

	同样，delete也是不会在SSTable里把数据删除，而是使用tombstone来标记数据将要被删除。Tomstone会保存一段时间，它是由gc_grace_seconds这个配置项定义。

	在压缩过程中，磁盘利用率会达到一个临时的峰值，下图描述了压缩的过程：

	![compaction]({{ site.baseurl }}/img/cassandra03/compaction.png)

	压缩过程中，每个SSTable里的数据会根据partition key进行合并，根据timestamp选取最新的那条数据。cassandra合并数据是非常高效的，因为在每个SSTable里的行都是根据partition key来排序。删除完被标记了tombstones的数据，压缩进程会把SSTables更新到一个新的文件。就得SSTable则会在所有等待的读完成后删除。然后旧的SSTable所占空间则可被重用。

	你可以配置以下3种压缩类型：

	* [SizeTieredCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) : 业务类型是写敏感的
	* [LeveledCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) ：业务类型是读敏感的
	* [LeveledCompactionStrategy](http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html?scroll=tabProp__moreCompaction) ：[ time series data ](http://planetcassandra.org/blog/getting-started-with-time-series-data-modeling/) 和 [expiring (TTL) data](http://docs.datastax.com/en/cql/3.1/cql/cql_using/use_expire_c.html)

## 索引存储和更新
	
在cassandra里，索引是一个数据分区。例如在palylist的例子里，为artist字段创建索引，cassandra根据playlist id作为partition key把数据保存到不同的节点上，每个节点会为自己拥有的artist信息创建索引。

和关系型数据库一样，更新索引也不是完全没有消耗的，所以不要创建无谓的索引。当一列数据被更新，索引页也需要更新。

# delete
---------------------------------

Cassandra删除数据的方式与关系型数据库不一样，关系新数据库会先查找数据然后删除，而cassandra的数据将会有一个可选的属性：TTL（tiem to live）。通过使用CQL为数据设置TTL，cassandra将会把过期的数据标记tombstone，tombstone会存在gc_grace_seconds长的时间，并在compaction阶段把它删除。被删除的数据也是有可能被恢复的，因为删除某一个行数据时，拥有这数据的replica的节点挂了，而且挂的时间比较长，删除请求不能replay到那个节点上，那么数据就会保留在那个节点。

# Hinted handoff
----------------------------------

Hinted handoff是cassandra优化cluster consitency进程和cluster数据同步的特性。当某个节点不可用时，在一定的一致性level配置情况下，启用了hinted handoff可以保证写成功。

在写的过程中，假如需要保存replica的某个节点不可用（1.预先知道该节点不可用 2.向该节点发写请求没回应），并且符合一致性要求的情况下，coordinator(接收到客户端发来的写请求的节点)将会保存replica的hint.hint包含了以下信息：

* 需要保存该replica节点位置
* version metadata
* 真正的数据

hints默认会被保存3个小时，因为超过3个小时那个节点还没起来可能永久的挂了。如果节点恢复了，保存hints的节点将会把数据重新发送给那个节点。

当W+R>replication factor的时候，写操作将会失败。其中W是block住写的节点，R是block住读的节点。例如cluster里有两个节点A和B，replication factor（RF）是1（即每一行数据只有一份），假设现在A挂了，并有一个要向A写的数据K的请求，一致性level是1，这时请求将会失败。因为一致性level是1，要求至少有一个replia可用，那么R=1，W=1，R+W=2>RF(=1）,所以写失败，hinted也不会保存。如果一个cluster里有3个节点,A(coordinator)/B和C，RF=2，每行数据都会存在于两个节点上。假如C挂了，一致性level是ONE，A节点接收到客户端的写请求，那么A将会往B写一份，自己也会保存hint。当C恢复，A将把数据转发给C。
![hinthandoff]({{ site.baseurl }}/img/cassandra03/hinthandoff.png)

## Extreme write availability

如果希望cassndra在所有replica的节点都down的情况下都成功接收写请求，那么就把一致性level设置为ANY，保证写是可持久化的，并且当合适的replica节点恢复后，那么数据就可读。


# Reads
---------------------------

Cassandra必须同时结合memtable和潜在的多个SSTables去完成一个读请求。首先，cassandra会检查bloom filter, bloom filter是一个off-heap（堆外内存）数据结构，关联着每个SSTable，记录了请求的数据行是否存在于SSTtable中，减少多余磁盘IO。

如果Bloom filter没有排除掉SSTable，cassandra会检查partition key cache会根据以下情况采取不同的action：

* 如果index entry在cache里找到：

	1. cassndra会去compression offset map里找到存储数据的compressed block
	2. 抓取compressed数据并返回结果

* 如果在cache没找到到index entry

	1. cassandra在partition summary里查找index entry的在磁盘中的大概位置。partiton summary是partition index 的子集，它会把每128个partition index中抽取一个放到partition summary，默认从index 1开始.而partition index保存了主键和数据在磁盘中的为位置。
	2. 然后抓取index entry
	3. 去compression offset map里找到存储数据的compressed block
	4. 抓取compressed数据并返回结果
![read]({{ site.baseurl }}/img/cassandra03/read.png)

## off-heap 组件对reads的影响

为了提高每个节点处理数据的能力，cassandra把以下组件放置到堆外内存上。

* bloom filter : 

	[bloom filter](http://billmill.org/bloomfilter-tutorial/)是用于查找某个数据是否在集合中的算法，它使用一个bit map标记某个数据是否存在，例如某个集合里有A数据，那么通过一个哈希函数算出A在bit map里的比特位置，并设置为1。那么要查找A时，用同样的哈希算法算出比特位置，假如这个位是1，代表A数据存在，如果是0，则不存在。
